---
layout:     post
title:      "KVM虚拟化之VM Exit/Entry"
subtitle:   ""
date:       2018-09-10
author:     "min"
header-img: "img/post-bg-2015.jpg"
tags:
    - qemu, kvm, virtualization
---
# KVM虚拟化之VM Exit/Entry

X86处理有4个特权级别Ring0~Ring3，只有运行在 Ring0 ~ 2级时，处理器才可以访问特权资源或执行特权指令。
运行在 Ring 0 级时，处理器可以访问所有的特权状态。Linux只使用Ring 0和Ring 3这两个级别，
操作系统运行在Ring 0级，用户进程运行在Ring 3级。

Intel硬件虚拟化技术VT-x。VT-x为处理器增加了两种操作模式：VMX root operation 和 VMX non-root operation。
VMM 自己运行在VMX root operation 模式，VMX non-root operation 模式则由Guest OS 使用。
两种操作模式都支持Ring 0 ~ Ring 3 这 4 个特权级，因此VMM和 Guest OS 都可以自由选择它们所期望的运行级别。

VMX（Virtual Machine Extension）通过引入根运行模式（VMX root operation）
和非根模式（VMX non-root operation），直接让vCPU运行在逻辑CPU上，在软件上省去了对vCPU运行的模拟，大大提升了性能。
剩下的就是对vCPU状态的记录了，为此Intel引入了VMCS（Virtual Machine Control Structure）功能。

## VMCS

VMM 和 Guest OS 共享底层的处理器资源，因此硬件需要一个物理内存区域来自动保存或恢复彼此执行的上下文。
这个区域称为虚拟机控制块（VMCS），包括客户机状态区（Guest State Area），主机状态区（Host State Area）和执行控制区。

## VM entry 

qemu-kvm进程调用kvm_exec_cpu函数初始化vcpu，最终通过kvm_vcpu_ioctl调用进入host kvm.mo内核进行处理
进入kvm.ko后的处理流程入下：

```commandline

kvm_vcpu_ioctl（kvm_main.c）-->kvm_arch_vcpu_ioctl_run(kvm/x86.c)
    -->vcpu_run(kvm/x86.c)-->vcpu_enter_guest(kvm/x86.c)
                                1. kvm_x86_ops->prepare_guest_switch(vcpu);
                                2. kvm_load_guest_xcr0(vcpu);
                                3. kvm_x86_ops->run(vcpu); 
                                4. 调用 -->vmx_vcpu_run(vmx.c) (store host stat & Enter guest mode)
```

第一次启动Guest，通过VMLAUNCH指令加载Guest，这时候一切都是新的，比如说起始的rip寄存器等。
后续Guest exit后再entry，是通过VMRESUME指令，此指令会将VMCS所指向的内容加载到当前Guest的上下文，
以便Guest继续执行。

##VM exit

Guest OS运行在VMX non-root模式中，当执行默写特权执行时，则会引发VM Exit。
有几种情况会导致VM exit，比如说Guest执行了硬件访问操作，
或者Guest调用了VMCALL指令或者调用了退出指令或者产生了一个page fault，或者访问了特殊设备的寄存器等。
当产生VM exit的时候，CPU会将exit reason保存到`MSRs`（VMX模式的特殊寄存器组），
对应到KVM就是vCPU->kvm_run->exit_reason。KVM根据exit_reason做相应的处理。

VM Exit退出的代码是`vmx.c:vmx_vcpu_run`函数后半段开始执行，执行路径与vm entry相反，一层层回调处理到qemu-kvm中的kvm_exec_cpu

由此可以见，当Guest OS需要执行root特权指令时，引发的VM Exist，其实时从用户态(qemu) -> 内核态（kvm）-> 用户态（qemu）
过程


官网的Architecture 对整个流程描述的非常清晰 
[!arch](https://wiki.qemu.org/Documentation/Architecture)


## KVM Makefile

kvm kernel moduler Makefile，由此可见host kernel的kvm包含两部分代码`virt/kvm/`和`arch/x86/kvm`
不同的硬件虚拟化对应不同的mode，如`kvm-intel.ko` 包含`vmx.c`和`pmu_intel.c`，而amd硬件虚拟化则是
`svm.c`和`pmu_amd.c`

```commandline
# SPDX-License-Identifier: GPL-2.0

ccflags-y += -Iarch/x86/kvm

CFLAGS_x86.o := -I.
CFLAGS_svm.o := -I.
CFLAGS_vmx.o := -I.

KVM := ../../../virt/kvm

kvm-y			+= $(KVM)/kvm_main.o $(KVM)/coalesced_mmio.o \
				$(KVM)/eventfd.o $(KVM)/irqchip.o $(KVM)/vfio.o
kvm-$(CONFIG_KVM_ASYNC_PF)	+= $(KVM)/async_pf.o

kvm-y			+= x86.o mmu.o emulate.o i8259.o irq.o lapic.o \
			   i8254.o ioapic.o irq_comm.o cpuid.o pmu.o mtrr.o \
			   hyperv.o page_track.o debugfs.o

kvm-intel-y		+= vmx.o pmu_intel.o
kvm-amd-y		+= svm.o pmu_amd.o

obj-$(CONFIG_KVM)	+= kvm.o
obj-$(CONFIG_KVM_INTEL)	+= kvm-intel.o
obj-$(CONFIG_KVM_AMD)	+= kvm-amd.o

```

## kvm模块初始化

kvm模块初始化创建了`/dev/kvm`的micsdevice的设备，从而可以使得用户态的程序通过`/dev/kvm`设备与kvm模块交互。
```commandline
static struct file_operations kvm_chardev_ops = {
	.unlocked_ioctl = kvm_dev_ioctl,
	.llseek		= noop_llseek,
	KVM_COMPAT(kvm_dev_ioctl),
};

static struct miscdevice kvm_dev = {
	KVM_MINOR,
	"kvm",
	&kvm_chardev_ops,
};
```

`qemu-kvm/kvm_all.c:kvm_init` qemu-kvm用户态初始化通过
```commandline
s->fd = qemu_open("/dev/kvm", O_RDWR)
```
即建立了qemu和kvm.ko之间的联系。
